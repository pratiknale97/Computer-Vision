
-> PROJECT CONTENT
1. WORKING WITH IMAGES AND CNN BUILDING BLOCKS

      1. Agenda and Image Basics
      2. Looking at an image as a bunch of pixel values 
      3. Types of images – Greyscale, Binary, colour
      4. Image formats – RAW, JPEG, PNG etc. 
      5. Displaying images in python environment using PIL and Matplotlib
      6. Image Operations
      7. Sampling and quantization of 1D and 2D continuous signals
      8. Approximation of an arc in the digital space
      9. Definition of a Picture
      10. Resolution of a picture
      11. Images - Feature Extraction
      12. Recap on what an image is
      13. Domain and Range in the context of an image
      14. Understanding a Histogram
      15. Correlation and convolution of a dummy image grid with a kernel
      16. Concept of Filtering with examples
      17. Hands-on Python Demo: Working with images
      18. Getting familiar with using an image in python
      19. Building a simple Averaging Filter from scratch
      20. Introduction to Convolutions
      21. Convolutional Neural Network vs plain Neural Network
      22. Need for Convolutional as an alternative to a plain neural network
      23. Translational invariance
      24. A simple demonstration of convolution using a 1D array
      25. 2D convolutions for Images 
      26. Demonstration of convolution on a simple 2D image, using manual calculations Convolution - Forward
      27. Demonstration of convolution using a dummy array, in Tensorflow
      28. Demonstration of convolution using an image in Tensorflow
      28. Convolution - Forward & Backward Prop
      28. Recap of convolution during forwarding path
      29. Demo of convolution during backward prop using a simple example
      30. Transposed Convolution and Fully Connected Layer as a Convolution
      31. Dilated convolution
      32. Deconvolution/Transposed convolution
      33. Implementation of convolution to mimic a fully connected layer
      34. Key points to remember when converting from linear to convolution
      35. Pooling: Max Pooling and Other pooling options
      36. Explanation of pooling and specifically max pooling and average pooling?
      37. Demo of max pooling with TensorFlow
      38. Max and average pooling during back prop
      39. Other pooling options
      40. Hands-on Keras Demo: MNIST CNN Building Blocks code walk-through
      41. Implementation of CNN in Keras framework, using MNIST dataset

2. CNN ARCHITECTURES AND TRANSFER LEARNING

      1. CNN Architectures and LeNet Case Study
      2. Two major challenge-datasets – MNIST and IMAGENET 
      3. Discussion on LeNet for MNIST 
      4. Discussion on various CNNs built for IMAGENET challenge
      5. The network architecture of LeNet-5
      6. Case Study: AlexNet
      7. Architecture o AlexNet in detail
      8. Case Study: ZFNet and VGGNet
      9. Performance and architecture of ZFNet
      10. Performance and architecture of VGGNet in detail
      11. Case Study: GoogleNet
      12. Architecture and performance of GoogleNet in detail
      13. Case Study: ResNet
      14. Performance comparison of all the architectures until now
      15. Architecture comparison of VGGNet and ResNet
      16. ResNet vs Plain NN
      16. Key points about ResNet
      17. The idea behind Squeeze and Excitation Network
      18. Why use ConvNets? And a brief summary of the evolution of CNN
      19. GPU vs CPU
      20. How GPU is different from CPU? 
      21. Comparison of the speed of execution of CPU and GPU
      22. Transfer Learning Principles and Practice
      23. Transfer learning as a smart workaround to enable the use of CNNs on
      24. smaller datasets
      25. Some standard practices when implementing transfer learning
      25. A brief discussion on transfer learning for image captioning
      26. Hands-on Transfer Learning: SVHN Transfer learning from MNIST dataset
      27. Using a network trained on MNIST to classify SVHN digits to demonstrate
      28. Transfer learning Visualization (run package, occlusion experiment)
      29. The idea behind visualizing CNNs
      30. Visualize patches that maximally activate neurons
      31. Visualize the filters/kernels (weights)
      32. Visualize the representation space
      33. Occlusion space 
      34. Addressing the Universal approximation theorem and the need for deep neural networks
      35. Hands-on demo -T-SNE
      36. Creating T-SNE embedding of each MNIST image to visualize in 2D 

3.OBJECT DETECTION

      1. Object Detection
      2. What is localization?
      3. How localization is achieved
      4. Faster R-CNN - architecture and workflow
      5. Performances Metrics
      6. IoU (Intersection over Union)
      7. Precision & Recall
      8. mAP (Mean Average Precision)
      9. Hands-On - Transfer Learning
      10. MNIST Data set - Transfer Learning Exercise
      11. Hands-On - Object Localization Using Bounding Boxes
      12. Extensive hands-on, on detecting bounding box
      13. Different Object Detection Techniques
      14. YOLO
      15. Fast R-CNN
      16. SSD

4. Semantic Segmentation

      1. Image Segmentation
      2. Meaning of Semantic segmentation
      3. Recap of CNN architecture
      4. What is padding and why do we need it?
      5. At a high level, how the architecture uses surrounding pixels to get the spatial context of a certain pixel, to classify/label that pixel
      6. Addressing the issue of Double-convolution or redundant convolutions
      7. Clarification on what is the input and what we expect as an output
      8. Semantic Segmentation process
      9. Pooling, as a way to decrease the size of individual feature map as well as increase the receptive field of each pixel of each feature map
      10. Need for and ways to up-sample/un-pool
      11. Hour-glass structure of the CNN used for semantic segmentation
      12. Challenge with the hour-glass structure and a workaround for that
      13. Semantic Segmentation U-Net Architecture
      14. The workflow of U-Net architecture
      15. Sample output for nucleus segmentation in pathology
      16. Hands-on demo - Semantic Segmentation using U-Net
      17. Demonstration of Semantic Segmentation using U-Net architecture
      18. Instance Segmentation
      19. Mask R-CNN
      20. Class Imbalance
      
PART I consists of task to train and compare image classifier models using supervised learning classifier, neural network classifier 
and a CNN classifier.
    -> DATA DESCRIPTION : The dataset comprises of images from 12 plant species.
    -> PROJECT OBJECTIVE : Require an automation which can create a classifier capable of determining a plant's species from a photo.

PART II consists of explaining observations how CNN outperforms other models.

PART III consists of curating an image dataset from scratch.
    -> TASK DESCRIPTION : Help to build the image dataset to be used by the AI team to build an image classifier data.
    Import and display the images in python against their labels.
    Comment on the challenges faced during this task.

PART IV consists of task to train and compare image classifier models using supervised learning classifier, neural network classifier 
and a CNN classifier. 
    -> DATA DESCRIPTION : The dataset comprises of images from 17 plant species. It can be downloaded from TensorFlow
    [ Hint: import tflearn.datasets.oxflower17 as oxflower17 ]
    -> PROJECT OBJECTIVE : Company’s management requires an automation which can create a classifier capable of determining a flower’s species from a photo.

PART V consists of explaining observations how CNN outperforms other models.
